---
layout:     post
title:      "Stereo Reconstruction"
date:       2020-3-6
author:     Tong
catalog: true
tags:
    - Reconstruction
---

### Efficient joint segmentation, occlusion labeling, stereo and flow estimation [^Yamaguchi14]

#### Abstract

### Accurate Multiple View 3D Reconstruction Using Patch-Based Stereo for Large-Scale Scenes [^Shen13]

#### Abstract 

### High accuracy and visibility-consistent dense multiview stereo [^Vu11]

#### Abstract

Since the initial comparison of Seitz et al. [^Seitz06], the accuracy of dense multiview stereovision methods has been increasing steadily. A number of limitations, however, make most of these methods not suitable to outdoor scenes taken under uncontrolled imaging conditions. The present work consists of a complete dense multiview stereo pipeline which circumvents these limitations, being able to handle large-scale scenes without sacrificing accuracy. Highly detailed reconstructions are produced within very reasonable time thanks to two key stages in our pipeline: a minimum s-t cut optimization over an adaptive domain that robustly and efficiently filters a quasidense point cloud from outliers and reconstructs an initial surface by integrating visibility constraints, followed by a mesh-based variational refinement that captures small details, smartly handling photo-consistency, regularization, and adaptive resolution. The pipeline has been tested over a wide range of scenes: from classic compact objects taken in a laboratory setting, to outdoor architectural scenes, landscapes, and cultural heritage sites. The accuracy of its reconstructions has also been measured on the dense multiview benchmark proposed by Strecha et al. [^Strecha08], showing the results to compare more than favorably with the current state-of-the-art methods.

#### Contributions

Our multiview stereo method consists of a pipeline that naturally handles large-scale open scenes while providing very accurate reconstructions within a very reasonable time. The whole pipeline is designed to not sacrifice accuracy for scalability. Several design choices are made and justified by an analysis of the weak points of other methods. The pipeline contains three main steps:
1. The generation of a quasidense point cloud with standard passive multiview stereo techniques.
2. The extraction of a mesh that respects visibility constraints and is close to the final reconstruction, with a minimum s-t cut-based optimization to fit a surface over the Delaunay triangulation of the points.
3. The variational refinement of this initial mesh to optimize its photo-consistency.

#### Background

- Delaunay Triangulation
- Surface Optimization with Minimum s-t Cut
- Dynamic Meshes: From Continuous to Discrete Gradient Flow

#### Multiview reconstruction pipeline

- Given calibrated cameras associated with the input images, 
    - a quasidense set of points is first extracted from the images. These points are matched pairwise between different views: From these matches, a quasidense 3D point cloud is generated by reconstructing and optionally merging the triangulated 3D points.
    - This point cloud is then fed to the second stage, which builds a Delaunay triangulation from it and then robustly extracts an initial surface from the facets of this triangulation, filtering out most of the outliers.
    - Finally, the last step improves the quality of the recovered surface by refining it using a criterion mixing photoconsistency and fairness.

- Quasidense Point Cloud
    - Match of interest points
    - Sparse depth maps (plane sweeping) -> __preferred__

- Visibility-Based Surface Reconstruction
    - Optimal Tetrahedron Binary Labeling
    - Surface Visibility
    - Surface Quality

- Photometric Robust Variational Refinement [^Faugeras02]
    - Photo-Consistency Refinement
    - Regularization

- Discretization
    - Balance between Photo-Consistency and Regularization
    - Mesh Resolution

#### Implementation

- Computational geometry algorithms library [CGAL](http://www.cgal.org/) [^Boissonnat00] defines robust and efficient implementations of all the geometric data structures, primitives, queries, and traversals needed for our different algorithms.

- The [maxflow algorithm](http://www.adastral.ucl.ac.uk/~vladkolm/software.html) described in [^Boykov04] is used to compute a minimum s-t-cut of our specifically designed network graphs.

### Manhattan-world stereo [^Furukawa09]

#### Abstract

### Piecewise Planar City 3D Modeling from Street View Panoramic Sequences [^Micusik09]

#### Abstract

City environments often lack textured areas, contain repetitive structures, strong lighting changes and therefore are very difficult for standard 3D modeling pipelines. We present a novel unified framework for creating 3D city models which overcomes these difficulties by exploiting image segmentation cues as well as presence of dominant scene orientations and piecewise planar structures. Given panoramic street view sequences, we first demonstrate how to robustly estimate camera poses without a need for bundle adjustment and propose a multi-view stereo method which operates directly on panoramas, while enforcing the piecewise planarity constraints in the sweeping stage. At last, we propose a new depth fusion method which exploits the constraints of urban environments and combines advantages of volumetric and viewpoint based fusion methods. Our technique avoids expensive voxelization of space, operates directly on 3D reconstructed points through effective kd-tree representation, and obtains a final surface by tessellation of backprojections of those points into the reference image.

#### Introdution

- The contribution of this paper is a unified and complete pipeline for piecewise planar city 3D modeling from street view panoramic sequences. Namely, 
    1. we modify a method for pose estimation to exploit beneficial properties of the panoramic camera with one virtual optical center,
    2. we utilize dominant scene orientations and adopt superpixels in a modified Markov Random Field (MRF) based dense stereo reconstruction method, and 
    3. we introduce a new depth map fusion algorithm combining advantages taken from volumetric- and viewpoint-based fusion methods.

- Our technique avoids expensive voxelization of space, operates directly on 3D reconstructed points through an effective kd-tree representation. As the result, a textured triangulated surface mesh of an observed environment is obtained.

### Multi-View Stereo via Graph Cuts on the Dual of an Adaptive Tetrahedral Mesh [^Sinha07]

#### Abstract 

### Stereo Processing by Semiglobal Matching and Mutual Information[^Hirschmuller07]

#### Abstract

This paper describes the Semiglobal Matching (SGM) stereo method. It uses a pixelwise, Mutual Information (MI)-based matching cost for compensating radiometric differences of input images. Pixelwise matching is supported by a smoothness constraint that is usually expressed as a global cost function. SGM performs a fast approximation by pathwise optimizations from all directions. The discussion also addresses occlusion detection, subpixel refinement, and multibaseline matching. Additionally, postprocessing steps for removing outliers, recovering from specific problems of structured environments, and the interpolation of gaps are presented. Finally, strategies for processing almost arbitrarily large images and fusion of disparity images using orthographic projection are proposed. A comparison on standard stereo images shows that SGM is among the currently top-ranked algorithms and is best, if subpixel accuracy is considered. The complexity is linear to the number of pixels and disparity range, which results in a runtime of just 1-2 seconds on typical test images. An in depth evaluation of the MI-based matching cost demonstrates a tolerance against a wide range of radiometric transformations. Finally, examples of reconstructions from huge aerial frame and pushbroom images demonstrate that the presented ideas are working well on practical problems.

#### 1. Introduction

This paper describes the Semiglobal Matching (SGM) method [^Hirschmuller05], [^Hirschmuller06], which calculates the matching cost hierarchically by __Mutual Information__. __Cost aggregation__ is performed as approximation of a global energy function by pathwise optimizations from all directions through the image. __Disparity computation__ is done by winner takes all and supported by disparity refinements like consistency checking and subpixel interpolation. __Multibaseline matching__ is handled by fusion of disparities. Further __disparity refinements__ include peak filtering, intensity consistent disparity selection, and gap interpolation. Previously unpublished is the extension for matching almost arbitrarily large images and the fusion of several disparity images using orthographic projection.

#### 2. Semiglobal Matching

The Semiglobal Matching (SGM) method is based on the idea of pixelwise matching of Mutual Information and approximating a global, 2D smoothness constraint by combining many 1D constraints.

- 2.1 Pixelwise Matching Cost Calculation
    1. Input images are assumed to have a known epipolar geometry.
    2. The matching cost calculation can be based on Mutual Information (MI)[^Viola97], which is insensitive to recording and illumination changes. It is defined from the entropy $$H$$ of two images (that is, their information content), as well as their joint entropy:$$M I_{I_{1}, I_{2}}=H_{I_{1}}+H_{I_{2}}-H_{I_{1}, I_{2}}$$
    3. The entropies are calculated from the probability distributions $$P$$ of intensities of the associated images: $$\begin{aligned} H_{I} &=-\int_{0}^{1} P_{I}(i) \log P_{I}(i) d i \\ H_{I_{1}, I_{2}} &=-\int_{0}^{1} \int_{0}^{1} P_{I_{1}, I_{2}}\left(i_{1}, i_{2}\right) \log P_{I_{1}, I_{2}}\left(i_{1}, i_{2}\right) d i_{1} d i_{2} \end{aligned}$$
    4. The MI matching cost $$\begin{aligned} C_{M I}(\mathbf{p}, d) &=-m i_{I_{b}, f_{D}\left(I_{m}\right)}\left(I_{b \mathbf{p}}, I_{m \mathbf{q}}\right) \\ \mathbf{q} &=e_{b m}(\mathbf{p}, d) \end{aligned}$$
    5. An implementation of the hierarchical MI computation (HMI) would collect all alleged correspondences defined by an initial disparity (that is, up-scaled from previous hierarchical level or random in the beginning). From the correspondences, the probability distribution $$P$$ is calculated according to (6). The size of $$P$$ is the square of the number of intensities, which is constant (for example, $$256 \times 256$$). The subsequent operations consist of Gaussian convolutions of P and calculating the logarithm.$$P_{I_{1}, I_{2}}(i, k)=\frac{1}{n} \sum_{\mathbf{p}} \mathrm{T}\left[(i, k)=\left(I_{1 \mathrm{p}}, I_{2 \mathrm{p}}\right)\right] \quad (6)$$

- 2.2 Cost Aggregation
    1. An additional constraint is added that supports smoothness by penalizing changes of neighboring disparities. The pixelwise cost and the smoothness constraints are expressed by defining the energy $$E(D)$$ that depends on the disparity image $$D$$: 
    $$E(D)= \sum_{\mathbf{p}}\left(C\left(\mathbf{p}, D_{\mathbf{p}}\right)+\sum_{\mathbf{q} \in N_{\mathbf{p}}} P_{1} \mathbf{T}\left[\left|D_{\mathbf{p}}-D_{\mathbf{q}}\right|=1\right]\right. \left.+\sum_{\mathbf{q} \in N_{\mathbf{p}}} P_{2} \mathbf{T}\left[\left|D_{\mathbf{p}}-D_{\mathbf{q}}\right|>1\right]\right)$$
    2. Discontinuities are often visible as intensity changes. This is exploited by adapting $$P2$$ to the intensity gradient.
    3. Unfortunately, such a global minimization, that is, in 2D, is NP-complete for many discontinuity preserving energies[^Boykov01]. This leads to the new idea of aggregating matching costs in 1D from all directions equally.
    4. The aggregated (smoothed) cost $$S(p, d)$$ for a pixel $$p$$ and disparity $$d$$ is calculated by summing the costs of all 1D minimum cost paths that end in pixel $$p$$ at disparity $$d$$. $$\begin{aligned}L_{\mathbf{r}}(\mathbf{p}, d)=& C(\mathbf{p}, d)+\min \left(L_{\mathbf{r}}(\mathbf{p}-\mathbf{r}, d)\right.\\& L_{\mathbf{r}}(\mathbf{p}-\mathbf{r}, d-1)+P_{1} \\& L_{\mathbf{r}}(\mathbf{p}-\mathbf{r}, d+1)+P_{1} \\&\left.\min L_{\mathbf{r}}(\mathbf{p}-\mathbf{r}, i)+P_{2}\right)-\min _{k} L_{\mathbf{r}}(\mathbf{p}-\mathbf{r}, k)\end{aligned}$$

- 2.3 Disparity Computation
    - The disparity image $$D_b$$ that corresponds to the base image $$I_b$$ is determined as in local stereo methods by selecting for each pixel p the disparity $$d$$ that corresponds to the minimum cost. For subpixel estimation, a quadratic curve is fitted through the neighboring costs, that is, at the next higher and lower disparity, and the position of the minimum is calculated. Using a quadratic curve is theoretically justified only for correlation using the sum of squared differences. However, it is used as an approximation due to the simplicity of calculation. This supports fast computation.

- 2.4 Multibaseline Matching
    - Multibaseline matching is performed by pairwise matching between the base and all match images individually. The consistency check (Section 2.3) is used after pairwise matching for eliminating wrong matches at occlusions and many other mismatches. Finally, the resulting disparity images are fused by considering individual scalings.

- 2.5 Disparity Refinement
    - Removal of peaks
    - Intensity consistent disparity selection
    - Discontinuity reserving interpolation

- 2.6 Processing of Huge Images

- 2.7 Fusion of Disparity Images
    - First, the height data is segmented in the same way as described in Section 2.5.1 by allowing height values of neighboring grid cells within one segment to vary by a certain predefined amount. Each segment is considered to be a physical surface. Holes can exist within or between segments. The former are filled by Inverse Distance Weighted (IDW) interpolation from all valid pixels just next to the hole. The latter case is handled by only considering valid pixels of the segment whose pixel have the lowest mean compared to the valid bordering pixel of all other segments next to the hole. This strategy performs smooth interpolation but maintains height discontinuities by extrapolating the background. Using IDW instead of pathwise interpolation is computationally more expensive, but it is performed only once on the fused result and not on each disparity image individually.

### Real-time visibility-based fusion of depth maps [^Merrell07]

#### Abstract

### Multi-view stereo for community photo collections [^Goesele07]

#### Abstract

We present a multi-view stereo algorithm that addresses the extreme changes in lighting, scale, clutter, and other effects in large online community photo collections. Our idea is to intelligently choose images to match, both at a per-view and per-pixel level. We show that such adaptive view selection enables robust performance even with dramatic appearance variability. The stereo matching technique takes as input sparse 3D points reconstructed from structure-from-motion methods and iteratively grows surfaces from these points. Optimizing for surface normals within a photoconsistency measure significantly improves the matching results. While the focus of our approach is to estimate high-quality depth maps, we also show examples of merging the resulting depth maps into compelling scene reconstructions. We demonstrate our algorithm on standard multi-view stereo datasets and on casually acquired photo collections of famous scenes gathered from the Internet.

#### Introduction

- In this paper we present a stereo matching approach that starts from irregular distributions of viewpoints, and produces robust high-quality depth maps in the presence of extreme appearance variations.
- Our main contribution is the design and analysis of such an adaptive view selection process. 
- We also
    1. present a new multi-view stereo matching algorithm that uses a surface growing approach to iteratively reconstruct robust and accurate depth maps. This surface growing approach[^Otto89] takes as input sparse feature points, leveraging the success of structure-from-motion techniques [^Brown05][^Snavely06]  which produce such output and have recently been demonstrated to operate effectively on CPCs (community photo collections). 
    2. Instead of obtaining a discrete depth map, as is common in many stereo methods [^Scharstein02], we opt instead to reconstruct a sub-pixel-accurate continuous depth map. 
    3. To greatly improve resilience to appearance differences in the source views, we use a photometric window matching approach in which both surface depth and normal are optimized together, and we adaptively discard views that do not reinforce cross-correlation of the matched windows. 
    4. Used in conjunction with a depth-merging approach, the resulting approach is shown to be competitive with the current top-performing multi-view stereo reconstruction methods on the Middlebury benchmarks [^Seitz06].

#### Algorithm

- Our approach to reconstructing geometry from Internet collections consists of several stages. 
    1. First, we calibrate the cameras geometrically and radiometrically.
    2. Next, we estimate a depth map for each input image — each image serves as a reference view exactly once. In order to find good matches, we apply a two-level view selection algorithm. 
        1. At the image level, _global view selection_ identifies for each reference view a set of good neighborhood images to use for stereo matching. 
        2. Then, at the pixel level, _local view selection_ determines a subset of these images that yields a stable stereo match. This subset generally varies from pixel to pixel.

- Stereo matching is performed at each pixel by optimizing for both depth and normal, starting from an initial estimate provided by SIFT feature points or copied from previously computed neighbors. During the stereo optimization, poorly matching views may be discarded and new ones added according to the local view selection criteria. The traversal of pixels is prioritized by their estimated matching confidence. Pixels may be revisited and their depths updated if a higher-confidence match is found.

### Multi-View Stereo Revisited [^Goesele06]

#### Abstract

### Multi-camera Scene Reconstruction via Graph Cuts [^Kolmogorov02]

#### Abstract

### Photorealistic scene reconstruction by voxel coloring [^Seitz97]

#### Abstract

### Literature

[^Hirschmuller05]: Hirschmuller, Heiko. "Accurate and efficient stereo processing by semi-global matching and mutual information." 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05). Vol. 2. IEEE, 2005.

[^Hirschmuller06]: Hirschmuller, Heiko. "Stereo vision in structured environments by consistent semi-global matching." 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06). Vol. 2. IEEE, 2006.

[^Hirschmuller07]: Hirschmuller, Heiko. "Stereo processing by semiglobal matching and mutual information." IEEE Transactions on pattern analysis and machine intelligence 30.2 (2007): 328-341.

[^Viola97]: Viola, Paul, and William M. Wells III. "Alignment by maximization of mutual information." International journal of computer vision 24.2 (1997): 137-154.

[^Boykov01]: Boykov, Yuri, Olga Veksler, and Ramin Zabih. "Fast approximate energy minimization via graph cuts." IEEE Transactions on pattern analysis and machine intelligence 23.11 (2001): 1222-1239.

[^Micusik09]: Micusik, Branislav, and Jana Kosecka. "Piecewise planar city 3D modeling from street view panoramic sequences." 2009 IEEE Conference on Computer Vision and Pattern Recognition. IEEE, 2009.

[^Vu11]: Vu, Hoang-Hiep, et al. "High accuracy and visibility-consistent dense multiview stereo." IEEE transactions on pattern analysis and machine intelligence 34.5 (2011): 889-901.

[^Seitz06]: Seitz, Steven M., et al. "A comparison and evaluation of multi-view stereo reconstruction algorithms." 2006 IEEE computer society conference on computer vision and pattern recognition (CVPR'06). Vol. 1. IEEE, 2006.

[^Strecha08]: Strecha, Christoph, et al. "On benchmarking camera calibration and multi-view stereo for high resolution imagery." 2008 IEEE Conference on Computer Vision and Pattern Recognition. Ieee, 2008.

[^Furukawa09]: Furukawa, Yasutaka, et al. "Manhattan-world stereo." 2009 IEEE Conference on Computer Vision and Pattern Recognition. IEEE, 2009.

[^Faugeras02]: Faugeras, Olivier, and Renaud Keriven. Variational principles, surface evolution, PDE's, level set methods and the stereo problem. IEEE, 2002.

[^Boissonnat00]: J.-D. Boissonnat, O. Devillers, M. Teillaud, and M. Yvinec, “Triangulations in CGAL,” Proc. 16th Ann. Symp. Computational Geometry, pp. 11-18, 2000.

[^Boykov04]: Y. Boykov and V. Kolmogorov, “An Experimental Comparison of Min-Cut/Max-Flow Algorithms for Energy Minimization in Vision,” IEEE Trans. Pattern Analysis and Machine Intelligence, vol. 26, no. 9, pp. 1124-1137, Sept. 2004.

[^Yamaguchi14]: Yamaguchi, Koichiro, David McAllester, and Raquel Urtasun. "Efficient joint segmentation, occlusion labeling, stereo and flow estimation." European Conference on Computer Vision. Springer, Cham, 2014.

[^Sinha07]: Sinha, Sudipta N., Philippos Mordohai, and Marc Pollefeys. "Multi-View Stereo via Graph Cuts on the Dual of an Adaptive Tetrahedral Mesh." international conference on computer vision (2007): 1-8.

[^Kolmogorov02]: Kolmogorov, Vladimir, and Ramin Zabih. "Multi-camera Scene Reconstruction via Graph Cuts." european conference on computer vision (2002): 82-96.

[^Seitz97]: Seitz, Steven M., and Charles R. Dyer. "Photorealistic scene reconstruction by voxel coloring." computer vision and pattern recognition (1997): 1067-1073.

[^Merrell07]: Merrell, Paul, et al. "Real-time visibility-based fusion of depth maps." 2007 IEEE 11th International Conference on Computer Vision. IEEE, 2007.

[^Goesele06]: Goesele, Michael, Brian Curless, and Steven M. Seitz. "Multi-view stereo revisited." 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06). Vol. 2. IEEE, 2006.

[^Goesele07]: Goesele, Michael, et al. "Multi-view stereo for community photo collections." 2007 IEEE 11th International Conference on Computer Vision. IEEE, 2007.

[^Brown05]: M. Brown and D. G. Lowe. Unsupervised 3D object recognition and reconstruction in unordered datasets. In Proc. 3DIM, pages 56–63, 2005.

[^Snavely06]: N. Snavely, S. M. Seitz, and R. Szeliski. Photo tourism: exploring photo collections in 3D. In SIGGRAPH Conf. Proc., pages 835–846, 2006.

[^Scharstein02]: D. Scharstein and R. Szeliski. A taxonomy and evaluation of dense two-frame stereo correspondence algorithms. IJCV, 47(1):7–42, 2002.

[^Otto89]: G. P. Otto and T. K. W. Chau. ‘Region-growing’ algorithm for matching of terrain images. Image Vision Comput., 7(2):83–94, 1989.

[^Shen13]: S. Shen, "Accurate Multiple View 3D Reconstruction Using Patch-Based Stereo for Large-Scale Scenes," in IEEE Transactions on Image Processing, vol. 22, no. 5, pp. 1901-1914, May 2013.