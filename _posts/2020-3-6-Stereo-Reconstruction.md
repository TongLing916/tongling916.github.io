---
layout:     post
title:      "Stereo Reconstruction"
date:       2020-3-6
author:     Tong
catalog: true
tags:
    - Reconstruction
---

### Multi-view stereo: A tutorial [^Furukawa15]

#### Abstract

### Efficient joint segmentation, occlusion labeling, stereo and flow estimation [^Yamaguchi14]

#### Abstract

### High accuracy and visibility-consistent dense multiview stereo [^Vu2011]

#### Abstract

Since the initial comparison of Seitz et al. [^Seitz2006], the accuracy of dense multiview stereovision methods has been increasing steadily. A number of limitations, however, make most of these methods not suitable to outdoor scenes taken under uncontrolled imaging conditions. The present work consists of a complete dense multiview stereo pipeline which circumvents these limitations, being able to handle large-scale scenes without sacrificing accuracy. Highly detailed reconstructions are produced within very reasonable time thanks to two key stages in our pipeline: a minimum s-t cut optimization over an adaptive domain that robustly and efficiently filters a quasidense point cloud from outliers and reconstructs an initial surface by integrating visibility constraints, followed by a mesh-based variational refinement that captures small details, smartly handling photo-consistency, regularization, and adaptive resolution. The pipeline has been tested over a wide range of scenes: from classic compact objects taken in a laboratory setting, to outdoor architectural scenes, landscapes, and cultural heritage sites. The accuracy of its reconstructions has also been measured on the dense multiview benchmark proposed by Strecha et al. [^Strecha2008], showing the results to compare more than favorably with the current state-of-the-art methods.

#### Contributions

Our multiview stereo method consists of a pipeline that naturally handles large-scale open scenes while providing very accurate reconstructions within a very reasonable time. The whole pipeline is designed to not sacrifice accuracy for scalability. Several design choices are made and justified by an analysis of the weak points of other methods. The pipeline contains three main steps:
1. The generation of a quasidense point cloud with standard passive multiview stereo techniques.
2. The extraction of a mesh that respects visibility constraints and is close to the final reconstruction, with a minimum s-t cut-based optimization to fit a surface over the Delaunay triangulation of the points.
3. The variational refinement of this initial mesh to optimize its photo-consistency.

#### Background

- Delaunay Triangulation
- Surface Optimization with Minimum s-t Cut
- Dynamic Meshes: From Continuous to Discrete Gradient Flow

#### Multiview reconstruction pipeline

- Given calibrated cameras associated with the input images, 
    - a quasidense set of points is first extracted from the images. These points are matched pairwise between different views: From these matches, a quasidense 3D point cloud is generated by reconstructing and optionally merging the triangulated 3D points.
    - This point cloud is then fed to the second stage, which builds a Delaunay triangulation from it and then robustly extracts an initial surface from the facets of this triangulation, filtering out most of the outliers.
    - Finally, the last step improves the quality of the recovered surface by refining it using a criterion mixing photoconsistency and fairness.

- Quasidense Point Cloud
    - Match of interest points
    - Sparse depth maps (plane sweeping) -> __preferred__

- Visibility-Based Surface Reconstruction
    - Optimal Tetrahedron Binary Labeling
    - Surface Visibility
    - Surface Quality

- Photometric Robust Variational Refinement [^Faugeras02]
    - Photo-Consistency Refinement
    - Regularization

- Discretization
    - Balance between Photo-Consistency and Regularization
    - Mesh Resolution

#### Implementation

- Computational geometry algorithms library [CGAL](http://www.cgal.org/) [^Boissonnat00] defines robust and efficient implementations of all the geometric data structures, primitives, queries, and traversals needed for our different algorithms.

- The [maxflow algorithm](http://www.adastral.ucl.ac.uk/~vladkolm/software.html) described in [^Boykov04] is used to compute a minimum s-t-cut of our specifically designed network graphs.

### Piecewise Planar City 3D Modeling from Street View Panoramic Sequences [^Micusik09]

#### Abstract

City environments often lack textured areas, contain repetitive structures, strong lighting changes and therefore are very difficult for standard 3D modeling pipelines. We present a novel unified framework for creating 3D city models which overcomes these difficulties by exploiting image segmentation cues as well as presence of dominant scene orientations and piecewise planar structures. Given panoramic street view sequences, we first demonstrate how to robustly estimate camera poses without a need for bundle adjustment and propose a multi-view stereo method which operates directly on panoramas, while enforcing the piecewise planarity constraints in the sweeping stage. At last, we propose a new depth fusion method which exploits the constraints of urban environments and combines advantages of volumetric and viewpoint based fusion methods. Our technique avoids expensive voxelization of space, operates directly on 3D reconstructed points through effective kd-tree representation, and obtains a final surface by tessellation of backprojections of those points into the reference image.

#### Introdution

- The contribution of this paper is a unified and complete pipeline for piecewise planar city 3D modeling from street view panoramic sequences. Namely, 
    1. we modify a method for pose estimation to exploit beneficial properties of the panoramic camera with one virtual optical center,
    2. we utilize dominant scene orientations and adopt superpixels in a modified Markov Random Field (MRF) based dense stereo reconstruction method, and 
    3. we introduce a new depth map fusion algorithm combining advantages taken from volumetric- and viewpoint-based fusion methods.

- Our technique avoids expensive voxelization of space, operates directly on 3D reconstructed points through an effective kd-tree representation. As the result, a textured triangulated surface mesh of an observed environment is obtained.

### Global stereo reconstruction under second order smoothness priors [^Woodford08]

#### Abstract 

### Stereo Processing by Semiglobal Matching and Mutual Information[^Hirschmuller2007]

#### Abstract

This paper describes the Semiglobal Matching (SGM) stereo method. It uses a pixelwise, Mutual Information (MI)-based matching cost for compensating radiometric differences of input images. Pixelwise matching is supported by a smoothness constraint that is usually expressed as a global cost function. SGM performs a fast approximation by pathwise optimizations from all directions. The discussion also addresses occlusion detection, subpixel refinement, and multibaseline matching. Additionally, postprocessing steps for removing outliers, recovering from specific problems of structured environments, and the interpolation of gaps are presented. Finally, strategies for processing almost arbitrarily large images and fusion of disparity images using orthographic projection are proposed. A comparison on standard stereo images shows that SGM is among the currently top-ranked algorithms and is best, if subpixel accuracy is considered. The complexity is linear to the number of pixels and disparity range, which results in a runtime of just 1-2 seconds on typical test images. An in depth evaluation of the MI-based matching cost demonstrates a tolerance against a wide range of radiometric transformations. Finally, examples of reconstructions from huge aerial frame and pushbroom images demonstrate that the presented ideas are working well on practical problems.

#### 1. Introduction

This paper describes the Semiglobal Matching (SGM) method [^Hirschmuller2005], [^Hirschmuller2006], which calculates the matching cost hierarchically by __Mutual Information__. __Cost aggregation__ is performed as approximation of a global energy function by pathwise optimizations from all directions through the image. __Disparity computation__ is done by winner takes all and supported by disparity refinements like consistency checking and subpixel interpolation. __Multibaseline matching__ is handled by fusion of disparities. Further __disparity refinements__ include peak filtering, intensity consistent disparity selection, and gap interpolation. Previously unpublished is the extension for matching almost arbitrarily large images and the fusion of several disparity images using orthographic projection.

#### 2. Semiglobal Matching

The Semiglobal Matching (SGM) method is based on the idea of pixelwise matching of Mutual Information and approximating a global, 2D smoothness constraint by combining many 1D constraints.

- 2.1 Pixelwise Matching Cost Calculation
    1. Input images are assumed to have a known epipolar geometry.
    2. The matching cost calculation can be based on Mutual Information (MI)[^Viola1997], which is insensitive to recording and illumination changes. It is defined from the entropy $$H$$ of two images (that is, their information content), as well as their joint entropy:$$M I_{I_{1}, I_{2}}=H_{I_{1}}+H_{I_{2}}-H_{I_{1}, I_{2}}$$
    3. The entropies are calculated from the probability distributions $$P$$ of intensities of the associated images: $$\begin{aligned} H_{I} &=-\int_{0}^{1} P_{I}(i) \log P_{I}(i) d i \\ H_{I_{1}, I_{2}} &=-\int_{0}^{1} \int_{0}^{1} P_{I_{1}, I_{2}}\left(i_{1}, i_{2}\right) \log P_{I_{1}, I_{2}}\left(i_{1}, i_{2}\right) d i_{1} d i_{2} \end{aligned}$$
    4. The MI matching cost $$\begin{aligned} C_{M I}(\mathbf{p}, d) &=-m i_{I_{b}, f_{D}\left(I_{m}\right)}\left(I_{b \mathbf{p}}, I_{m \mathbf{q}}\right) \\ \mathbf{q} &=e_{b m}(\mathbf{p}, d) \end{aligned}$$
    5. An implementation of the hierarchical MI computation (HMI) would collect all alleged correspondences defined by an initial disparity (that is, up-scaled from previous hierarchical level or random in the beginning). From the correspondences, the probability distribution $$P$$ is calculated according to (6). The size of $$P$$ is the square of the number of intensities, which is constant (for example, $$256 \times 256$$). The subsequent operations consist of Gaussian convolutions of P and calculating the logarithm.$$P_{I_{1}, I_{2}}(i, k)=\frac{1}{n} \sum_{\mathbf{p}} \mathrm{T}\left[(i, k)=\left(I_{1 \mathrm{p}}, I_{2 \mathrm{p}}\right)\right] \quad (6)$$

- 2.2 Cost Aggregation
    1. An additional constraint is added that supports smoothness by penalizing changes of neighboring disparities. The pixelwise cost and the smoothness constraints are expressed by defining the energy $$E(D)$$ that depends on the disparity image $$D$$: 
    $$E(D)= \sum_{\mathbf{p}}\left(C\left(\mathbf{p}, D_{\mathbf{p}}\right)+\sum_{\mathbf{q} \in N_{\mathbf{p}}} P_{1} \mathbf{T}\left[\left|D_{\mathbf{p}}-D_{\mathbf{q}}\right|=1\right]\right. \left.+\sum_{\mathbf{q} \in N_{\mathbf{p}}} P_{2} \mathbf{T}\left[\left|D_{\mathbf{p}}-D_{\mathbf{q}}\right|>1\right]\right)$$
    2. Discontinuities are often visible as intensity changes. This is exploited by adapting $$P2$$ to the intensity gradient.
    3. Unfortunately, such a global minimization, that is, in 2D, is NP-complete for many discontinuity preserving energies[^Boykov2001]. This leads to the new idea of aggregating matching costs in 1D from all directions equally.
    4. The aggregated (smoothed) cost $$S(p, d)$$ for a pixel $$p$$ and disparity $$d$$ is calculated by summing the costs of all 1D minimum cost paths that end in pixel $$p$$ at disparity $$d$$. $$\begin{aligned}L_{\mathbf{r}}(\mathbf{p}, d)=& C(\mathbf{p}, d)+\min \left(L_{\mathbf{r}}(\mathbf{p}-\mathbf{r}, d)\right.\\& L_{\mathbf{r}}(\mathbf{p}-\mathbf{r}, d-1)+P_{1} \\& L_{\mathbf{r}}(\mathbf{p}-\mathbf{r}, d+1)+P_{1} \\&\left.\min L_{\mathbf{r}}(\mathbf{p}-\mathbf{r}, i)+P_{2}\right)-\min _{k} L_{\mathbf{r}}(\mathbf{p}-\mathbf{r}, k)\end{aligned}$$

- 2.3 Disparity Computation
    - The disparity image $$D_b$$ that corresponds to the base image $$I_b$$ is determined as in local stereo methods by selecting for each pixel p the disparity $$d$$ that corresponds to the minimum cost. For subpixel estimation, a quadratic curve is fitted through the neighboring costs, that is, at the next higher and lower disparity, and the position of the minimum is calculated. Using a quadratic curve is theoretically justified only for correlation using the sum of squared differences. However, it is used as an approximation due to the simplicity of calculation. This supports fast computation.

- 2.4 Multibaseline Matching
    - Multibaseline matching is performed by pairwise matching between the base and all match images individually. The consistency check (Section 2.3) is used after pairwise matching for eliminating wrong matches at occlusions and many other mismatches. Finally, the resulting disparity images are fused by considering individual scalings.

- 2.5 Disparity Refinement
    - Removal of peaks
    - Intensity consistent disparity selection
    - Discontinuity reserving interpolation

- 2.6 Processing of Huge Images

- 2.7 Fusion of Disparity Images
    - First, the height data is segmented in the same way as described in Section 2.5.1 by allowing height values of neighboring grid cells within one segment to vary by a certain predefined amount. Each segment is considered to be a physical surface. Holes can exist within or between segments. The former are filled by Inverse Distance Weighted (IDW) interpolation from all valid pixels just next to the hole. The latter case is handled by only considering valid pixels of the segment whose pixel have the lowest mean compared to the valid bordering pixel of all other segments next to the hole. This strategy performs smooth interpolation but maintains height discontinuities by extrapolating the background. Using IDW instead of pathwise interpolation is computationally more expensive, but it is performed only once on the fused result and not on each disparity image individually.


### Literature

[^Hirschmuller2005]: Hirschmuller, Heiko. "Accurate and efficient stereo processing by semi-global matching and mutual information." 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05). Vol. 2. IEEE, 2005.

[^Hirschmuller2006]: Hirschmuller, Heiko. "Stereo vision in structured environments by consistent semi-global matching." 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06). Vol. 2. IEEE, 2006.

[^Hirschmuller2007]: Hirschmuller, Heiko. "Stereo processing by semiglobal matching and mutual information." IEEE Transactions on pattern analysis and machine intelligence 30.2 (2007): 328-341.

[^Viola1997]: Viola, Paul, and William M. Wells III. "Alignment by maximization of mutual information." International journal of computer vision 24.2 (1997): 137-154.

[^Boykov2001]: Boykov, Yuri, Olga Veksler, and Ramin Zabih. "Fast approximate energy minimization via graph cuts." IEEE Transactions on pattern analysis and machine intelligence 23.11 (2001): 1222-1239.

[^Micusik09]: Micusik, Branislav, and Jana Kosecka. "Piecewise planar city 3D modeling from street view panoramic sequences." 2009 IEEE Conference on Computer Vision and Pattern Recognition. IEEE, 2009.

[^Woodford08]: Woodford, O. J., Torr, P. H. S., Reid, I. D., & Fitzgibbon, A. W. (2008). Global stereo reconstruction under second order smoothness priors. 2008 IEEE Conference on Computer Vision and Pattern Recognition. 

[^Vu2011]: Vu, Hoang-Hiep, et al. "High accuracy and visibility-consistent dense multiview stereo." IEEE transactions on pattern analysis and machine intelligence 34.5 (2011): 889-901.

[^Seitz2006]: Seitz, Steven M., et al. "A comparison and evaluation of multi-view stereo reconstruction algorithms." 2006 IEEE computer society conference on computer vision and pattern recognition (CVPR'06). Vol. 1. IEEE, 2006.

[^Strecha2008]: Strecha, Christoph, et al. "On benchmarking camera calibration and multi-view stereo for high resolution imagery." 2008 IEEE Conference on Computer Vision and Pattern Recognition. Ieee, 2008.

[^Furukawa15]: Furukawa, Yasutaka, and Carlos Hernández. "Multi-view stereo: A tutorial." Foundations and Trends® in Computer Graphics and Vision 9.1-2 (2015): 1-148.

[^Faugeras02]: Faugeras, Olivier, and Renaud Keriven. Variational principles, surface evolution, PDE's, level set methods and the stereo problem. IEEE, 2002.

[^Boissonnat00]: J.-D. Boissonnat, O. Devillers, M. Teillaud, and M. Yvinec, “Triangulations in CGAL,” Proc. 16th Ann. Symp. Computational Geometry, pp. 11-18, 2000.

[^Boykov04]: Y. Boykov and V. Kolmogorov, “An Experimental Comparison of Min-Cut/Max-Flow Algorithms for Energy Minimization in Vision,” IEEE Trans. Pattern Analysis and Machine Intelligence, vol. 26, no. 9, pp. 1124-1137, Sept. 2004.

[^Yamaguchi14]: Yamaguchi, Koichiro, David McAllester, and Raquel Urtasun. "Efficient joint segmentation, occlusion labeling, stereo and flow estimation." European Conference on Computer Vision. Springer, Cham, 2014.